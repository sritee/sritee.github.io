<!DOCTYPE html>

<html>
    <head>
        <title>Projects</title>
        <!-- link to main stylesheet -->
        <link href="https://fonts.googleapis.com/css?family=Lato:300,400" rel="stylesheet">
        <link rel="stylesheet" type="text/css" href="/css/main_1.css">
    </head>
    <body>

        <nav>
    		<ul>
        		<li><a href="/">Home</a></li>
	        	<!-- <li><a href="/about">About</a></li> -->
        		<li><a href="/assets/Resume.pdf">R‌&#233;sum‌&#233;</a></li>
        		<li><a href="/projects.html">Experience</a></li>
    		</ul>
		</nav>
	
	<h4> Projects </h4>
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tr>
          <td width="25%">
            <div class="one">
                <iframe width="240" height="180" src="https://www.youtube.com/embed/YWjOEWO5lFs" frameborder="0" gesture="media" allowfullscreen></iframe>
            </div>
          </td>
          <td valign="top" width="75%">
            <anchor id="Clean_Beach" href=''></anchor>
            <p>Autonomous Beach Cleaning Robot</p>
            <i>SSN College of Engineering, India</i>
            <p2>Designed and Developed an Autonomous Beach Cleaning Robot in a team of 3. Involved in design and construction of mechanical prototype, and machine learning for litter detection. <br>
            <br></p2>
          </td>
        </tr>
        <tr>
          <td width="25%">
            <div class="one">
            <img src='/assets/Projects/AutonomousOvertaking.png' style="width:240px;height:140px;">
            </div>
          </td>
          <td valign="top" width="75%">
            <anchor id="Overtaker" href=''></anchor>
            <p>Temporally extended actions for Autonomous Overtaking</p>
            <i>Independent Research</i><br>
            <p2> Implemented and evaluated several papers in Reinforcement Learning's options framework- a framework for incorporation temporally extended actions. Conceptualized a scenario where this is used in the case of Autonomous Driving's Overtaking Scenario. </p2><br>
	    <a href="https://drive.google.com/file/d/1GiyIS0ApmTjjhtGblqLxovcqKf4UGYwi/view">[Tech Report]</a>| <a href="https://github.com/sritee/Diverse-Density-Estimation-for-Subgoal-Detection">[Code] </a> (implementation of one of the papers)
 
          </td>
        </tr>

        <tr>
          <td width="25%">
            <div class="one">
            <img src='/assets/Projects/Convex_Solver.png' style="width:240px;height:140px;">
            </div>
          </td>
          <td valign="top" width="75%">
            <anchor id="p_embedded1" href=''></anchor>
            <p>Convex Optimization Solver</p>
            <i>Independent Work</i><br>
            <p2> Primal Interior Point method for solving differentiable, convex problems. Written in MATLAB while reading Stephen Boyd's Convex Optimization book. </p2><br>
	    <a href="https://github.com/sritee/ConvexOpt-Interior-Point-Method"> [Github Repo] </a>
          </td>
        </tr>
        <tr>
          <td width="25%">
            <div class="one">
                <iframe width="240" height="180" src="https://www.youtube.com/watch?v=4e_sIKA7CKQ" frameborder="0" gesture="media" allowfullscreen></iframe>
            </div>
          </td>
          <td valign="top" width="75%">
            <anchor id="Gesture" href=''></anchor>
            <p>Hand Gesture Recognition using Convex hull defects</p>
            <i>SSN, Anna University</i><br>
            <p2> Segmenting the gesturer's hand and formulating the convex hull. The number shown was the function of the convexity defect's number and location. Written using C++ and OpenCV.<br>
            
          </td>
        </tr>
        <tr>
          <td width="25%">
            <div class="one">
            <img src='/assets/Projects/Kickstarter.jpg' style="width:240px;height:140px;">
	    </a>
          </td>
          <td valign="top" width="75%">
            <p>Kickstarter Campaign Success Prediction</p>
            <i>HackerEarth Contest</i><br>
            <p2> Feature Engineering competition to use of Supervised Learning Techniques to predict the sucess of a kickstarter campaign
            Code: <a href="https://github.com/sritee/Kickstarter-ML-Feature-Engineering-">[Code]</a><br></p2>
          </td>
        </tr>
      </table>

        <h4> Experience </h4>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
              <td width="25%">
                <div class="one">
                <!-- <div class="two"><img src='friendly_after.png'></div> -->
                <img src='/assets/Experience/Swaayatt_Intern.png' style="width:240px;height:140px;">
                </div>
              </td>
              <td valign="top" width="75%">
                  <p>Reinforcement Learning and Robotics Intern<br></p>
                  Ganesh Iyer, <a href="http://karnikram.info">Karnik Ram</a>, <a href="http://krrish94.github.io/">Krishna Murthy</a>, <a href="http://robotics.iiit.ac.in/">K. Madhava Krishna</a><br>
                <i>Robotics Research Center, IIIT-H</i><p2>   [Accepted to IROS 2018]</p2><br><br>
                <anchor id="p_swaayatt_stereo" href=''></anchor>
                <p2>CalibNet is a self-supervised deep network capable of automatically estimating the 6-DoF rigid body transformation for extrinsic calibration between a 3D LiDAR and a 2D camera in real-time, by maximizing the photometric and geometric consistency between the input images and point clouds. <a href="https://epiception.github.io/CalibNet/">[Project Page]</a> <a href="https://arxiv.org/abs/1803.08181">[Paper]</a> <br></p2>
              </td>
          </tr>
          <tr>
            <td width="25%">
              <div class="one">
              <!-- <div class="two"><img src='friendly_after.png'></div> -->
              <img src='/assets/Research/ctc.png' style="width:240px;height:150px;">
              </div>
            </td>
            <td valign="top" width="75%">
                <p>Geometric Consistency for Self-Supervised End-to-End Visual Odometry<br></p>
                Ganesh Iyer*, <a href="http://krrish94.github.io/">Krishna Murthy*</a>, <a href="https://gunshi.github.io/">Gunshi Gupta</a>, <a href="http://robotics.iiit.ac.in/">K. Madhava Krishna, </a><br> Liam Paull
                <anchor id="p_research_calib" href=''></anchor>
              <br>
              <i>Robotics Research Center, IIIT-H and Montreal Institute for Learning Algorithms, Université de Montréal</i><p2>   [Accepted to CVPR-Workshop 2018]</p2><br><br>
              <p2>We propose an unsupervised paradigm for deep visual odometry learning. We show that using a noisy teacher, which could be a standard VO pipeline, and by designing a loss term that enforces geometric consistency of the trajectory, we can train accurate deep models for VO that do not require ground-truth labels. We leverage geometry as a self-supervisory signal and propose "Composite Transformation Constraints (CTCs)", that automatically generate supervisory signals for training and enforce geometric consistency in the VO estimate
              <a href="https://krrish94.github.io/CTCNet-release/">[Project Page]</a> <a href="http://openaccess.thecvf.com/content_cvpr_2018_workshops/papers/w9/Iyer_Geometric_Consistency_for_CVPR_2018_paper.pdf">[Paper]</a> </p2>
            </td>
          </tr>
      </table>
      

      <footer>
          <a style="float: right; padding-top: 25px;" href="https://jonbarron.info/">Template Credits</a>
          <!-- <ul>
              <li><a href="mailto:giyer2309@gmail.com">email</a></li>
              <li><a href="https://github.com/epiception">github.com/epiception</a></li>
          </ul> -->
          <div class="footer-social-icons">
              <!-- <h4 class="_14">Follow us on</h4> -->
              <ul class="social-icons">
                  <li><a href="mailto:giyer2309@gmail.com" class="social-icon"> <i class="fa fa-envelope"></i></a></li>
                  <li><a href="https://www.linkedin.com/in/ganesh-iyer-0607bb112/" class="social-icon"> <i class="fa fa-linkedin"></i></a></li>
                  <li><a href="https://github.com/epiception" class="social-icon"> <i class="fa fa-github"></i></a></li>
                  <li><a href="https://www.youtube.com/user/giyer2309/videos?view_as=subscriber&sort=dd&view=0&shelf_id=0" class="social-icon"> <i class="fa fa-youtube"></i></a></li>
              </ul>
          </div>
      </footer>
    </body>

</html>
